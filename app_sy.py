import streamlit as st
import timm
import torch
import torch.nn as nn
from torchvision import datasets, transforms
from PIL import Image

DATA_DIR = "fabric_dataset"
MODEL_PATH = "model_sav/fabric_classifier_model_multitask_v0.6_64.pth"


# --- ë¸Œë¼ìš°ì € íƒ­ ---
st.set_page_config(
    page_title="IoLaundry",
    page_icon="ğŸ‘•",
    layout="wide"
)


# --- í´ë˜ìŠ¤ ì´ë¦„ ì •ì˜ ---
try:
    # ë°ì´í„°ì…‹ í´ë” êµ¬ì¡°ì—ì„œ í´ë˜ìŠ¤ ì´ë¦„ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
    temp_dataset = datasets.ImageFolder(root=DATA_DIR)
    FABRIC_CLASSES = temp_dataset.classes
    WASHING_CLASSES = ['machine_wash', 'delicate', 'dry_clean']
except FileNotFoundError:
    st.error(f"'{DATA_DIR}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•±ì´ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ë ¤ë©´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ë°ì´í„°ì…‹ í´ë”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    # í´ë”ê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ê¸°ë³¸ê°’
    FABRIC_CLASSES = ['Blended', 'Cotton', 'Denim', 'Fleece', 'Nylon', 'Polyester', 'Silk', 'Terrycloth', 'Viscose', 'Wool']
    WASHING_CLASSES = ['machine_wash', 'delicate', 'dry_clean']


# --- ëª¨ë¸ ì •ì˜ ---
class MultiTaskConvNeXt(nn.Module):
    def __init__(self, num_fabric_classes, num_washing_classes, task_type='multitask'):
        super().__init__()
        self.task_type = task_type
        # ëª¨ë¸ êµ¬ì¡°ë§Œ ì •ì˜, ê°€ì¤‘ì¹˜ëŠ” íŒŒì¼ì—ì„œ ë¡œë“œí•˜ë¯€ë¡œ pretrained=False
        self.backbone = timm.create_model('convnextv2_tiny', pretrained=False, features_only=True)
        feature_dim = self.backbone.feature_info[-1]['num_chs']     # num_chs : feature_map ì±„ë„ìˆ˜

        self.fabric_head = nn.Linear(feature_dim, num_fabric_classes)
        self.washing_head = nn.Linear(feature_dim, num_washing_classes)

    def forward(self, x):
        features = self.backbone(x)
        pooled_features = features[-1].mean(dim=(-1, -2))

        fabric_output = self.fabric_head(pooled_features)
        washing_output = self.washing_head(pooled_features)
        
        return fabric_output, washing_output


# --- ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ---
def preprocess_image(image):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    # ì±„ë„ìˆ˜ ë¬¸ì œ ë°©ì§€ (RGB ë³€í™˜)
    if image.mode != "RGB":
        image = image.convert("RGB")
    return transform(image).unsqueeze(0)


# --- ëª¨ë¸ ë¡œë“œ ---
@st.cache_resource
def load_model(model_path, task_type):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    num_fabric_classes = len(FABRIC_CLASSES)
    num_washing_classes = len(WASHING_CLASSES)
    
    model = MultiTaskConvNeXt(num_fabric_classes, num_washing_classes, task_type)
    
    try:
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ (strict=Falseë¡œ ì„¤ì •í•˜ì—¬ ë¶ˆì¼ì¹˜í•˜ëŠ” í‚¤ ë¬´ì‹œ)
        model.load_state_dict(torch.load(model_path, map_location=device), strict=False)
        model.to(device)
        model.eval() # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
        return model, None
    except Exception as e:
        return None, str(e)


model = None
task_type = 'multitask'
with st.spinner(f"ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
    model, error_msg = load_model(MODEL_PATH, task_type)
if error_msg:
    st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {error_msg}")
else :
    st.toast(f"**ëª¨ë¸ ë¡œë“œ ì™„ë£Œ**")


# --- ë©”ì¸í™”ë©´ UI ---
st.title("ğŸ‘• IoLaundry")
st.write("")
st.markdown("ì—…ë¡œë“œëœ ì‚¬ì§„ ë˜ëŠ” ì¹´ë©”ë¼ë¡œ ì´¬ì˜ëœ ì‚¬ì§„ì„ ë¶„ì„í•˜ì—¬ **ì›ë‹¨ ì¢…ë¥˜**ì™€ **ì ì ˆí•œ ì„¸íƒ ë°©ë²•**ì„ ì˜ˆì¸¡í•˜ëŠ” ì„œë¹„ìŠ¤")
st.markdown("---")

st.write("")
st.write("")
st.write("")
st.subheader("ğŸ“¸ ì´ë¯¸ì§€ ì…ë ¥")

tab1, tab2 = st.tabs(["ğŸ–¼ï¸ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ“· ì¹´ë©”ë¼ ì´¬ì˜"])
uploaded_image = None
with tab1 :
    uploaded_file = st.file_uploader("", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        uploaded_image = Image.open(uploaded_file)

with tab2 :
    camera_image = st.camera_input("")
    if camera_image:
        uploaded_image = Image.open(camera_image)

# --- ë¶„ì„ ë° ê²°ê³¼ ì¶œë ¥ ---
if uploaded_image is not None:
    st.write("")
    st.write("")
    st.write("")
    st.header("ğŸ” ë¶„ì„ ê²°ê³¼")
    col1, col2 = st.columns([1, 1.2])

    with col1:
        st.subheader("ì…ë ¥ ì‚¬ì§„")
        st.image(uploaded_image, caption="ë¶„ì„í•  ì‚¬ì§„", use_container_width =True)

    with col2:
        if model:
            placeholder = st.empty()  
            placeholder.subheader("ë¶„ì„ ì§„í–‰ ì¤‘...")
            with st.spinner('ëª¨ë¸ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡
                image_tensor = preprocess_image(uploaded_image).to(device)
                fabric_output, washing_output = model(image_tensor)
                
                # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
                predicted_fabric = "N/A"
                predicted_washing = "N/A"

                fabric_idx = torch.argmax(fabric_output, dim=1).item()
                washing_idx = torch.argmax(washing_output, dim=1).item()
                predicted_fabric = FABRIC_CLASSES[fabric_idx]
                predicted_washing = WASHING_CLASSES[washing_idx]

            placeholder.subheader("ì˜ˆì¸¡ ê²°ê³¼")
            st.success("ë¶„ì„ ì™„ë£Œ!")

            st.metric(label="ğŸ§µ **ì˜ˆìƒ ì›ë‹¨ ì¢…ë¥˜**", value=predicted_fabric)
            st.metric(label="ğŸ› **ê¶Œì¥ ì„¸íƒ ë°©ë²•**", value=predicted_washing)

        else:
            st.error("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.info("â¬†ï¸ ìœ„ì—ì„œ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì¹´ë©”ë¼ë¡œ ì´¬ì˜í•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")

st.markdown("---")
st.caption("<p style='text-align: right;'>Â© 2025 IoLaundry</p>", unsafe_allow_html=True)

